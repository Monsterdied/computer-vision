{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57559f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the parent directory path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d0555",
   "metadata": {},
   "source": [
    "Load the images names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be4332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images to be processed:  ['../images1/G000_IMG062.jpg', '../images1/G000_IMG087.jpg', '../images1/G000_IMG102.jpg', '../images1/G006_IMG048.jpg', '../images1/G006_IMG086.jpg', '../images1/G006_IMG119.jpg', '../images1/G019_IMG082.jpg', '../images1/G028_IMG015.jpg', '../images1/G028_IMG062.jpg', '../images1/G028_IMG098.jpg', '../images1/G028_IMG101.jpg', '../images1/G033_IMG043.jpg', '../images1/G033_IMG075.jpg', '../images1/G033_IMG088.jpg', '../images1/G033_IMG101.jpg', '../images1/G038_IMG074.jpg', '../images1/G038_IMG088.jpg', '../images1/G038_IMG103.jpg', '../images1/G038_IMG105.jpg', '../images1/G041_IMG042.jpg', '../images1/G041_IMG048.jpg', '../images1/G041_IMG088.jpg', '../images1/G041_IMG098.jpg', '../images1/G047_IMG053.jpg', '../images1/G047_IMG068.jpg', '../images1/G047_IMG102.jpg', '../images1/G047_IMG107.jpg', '../images1/G056_IMG017.jpg', '../images1/G056_IMG077.jpg', '../images1/G056_IMG097.jpg', '../images1/G058_IMG044.jpg', '../images1/G058_IMG074.jpg', '../images1/G058_IMG100.jpg', '../images1/G061_IMG080.jpg', '../images1/G061_IMG092.jpg', '../images1/G061_IMG098.jpg', '../images1/G072_IMG083.jpg', '../images1/G072_IMG098.jpg', '../images1/G076_IMG072.jpg', '../images1/G076_IMG089.jpg', '../images1/G076_IMG095.jpg', '../images1/G078_IMG092.jpg', '../images1/G083_IMG073.jpg', '../images1/G083_IMG089.jpg', '../images1/G087_IMG093.jpg', '../images1/G087_IMG099.jpg', '../images1/G091_IMG053.jpg', '../images1/G091_IMG074.jpg', '../images1/G091_IMG102.jpg', '../images1/G099_IMG094.jpg']\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "dataDir = \"../images1/\"\n",
    "for img in os.listdir(dataDir):\n",
    "\n",
    "    #join the path with the names of the images\n",
    "    dataDirTemp = os.path.join(dataDir, str(img))\n",
    "    images.append(dataDirTemp)\n",
    "print(\"Images to be processed: \", images)\n",
    "#Debug\n",
    "#images = images[7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d87d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def findHorse(img_original, x_offset=0, y_offset=0, width_box=30, height_box=30,debug=False):\n",
    "    \"\"\"\n",
    "    Draws boxes at the four corners of an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - img: Input image (BGR format)\n",
    "    - x_offset, y_offset: Offset for corner positions\n",
    "    - width_box, height_box: Size of the corner boxes\n",
    "    \"\"\"\n",
    "    img = img_original.copy()\n",
    "    # Convert to grayscale (though we'll draw on the original color image)\n",
    "    black_and_white = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = black_and_white.shape[:2]\n",
    "    \n",
    "    # Define the four corners with optional offsets\n",
    "    corners = [\n",
    "        (x_offset, height - 1 - height_box - y_offset),            # Bottom-left\n",
    "        (y_offset, x_offset),                          # Top-left\n",
    "        (width - 1 - height_box - y_offset, height - 1 - width_box - x_offset), # Bottom-right\n",
    "        (width - 1 - width_box - x_offset , y_offset)             # Top-right\n",
    "    ]\n",
    "    convert = [\"top_left\",  \"bottom_left\",\"top_right\", \"bottom_right\"]\n",
    "    # Create a list to hold all box contours\n",
    "    all_contours = []\n",
    "    intensities = []\n",
    "    count = 1\n",
    "    for (x, y) in corners:\n",
    "        if count%2 ==0:\n",
    "            temp = width_box\n",
    "            width_box = height_box\n",
    "            height_box = temp\n",
    "        count += 1\n",
    "        # Define a rectangle (box) around the corner point\n",
    "        box = np.array([\n",
    "            [x, y],                          # Top-left of the box\n",
    "            [x + width_box, y],               # Top-right of the box\n",
    "            [x + width_box, y + height_box],  # Bottom-right of the box\n",
    "            [x, y + height_box]               # Bottom-left of the box\n",
    "        ], dtype=np.int32)\n",
    "        \n",
    "        all_contours.append(box)\n",
    "        mask = np.zeros_like(black_and_white, dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [box], -1, 255, -1)  # Fill the contour (thickness=-1)\n",
    "        mean_intensity = cv2.mean(black_and_white, mask=mask)[0]\n",
    "        intensities.append(mean_intensity)\n",
    "    index = np.argmin(intensities)\n",
    "\n",
    "    # Draw all the box contours on the original image\n",
    "    cv2.drawContours(\n",
    "        img,\n",
    "        [all_contours[index]],\n",
    "        #all_contours,\n",
    "        contourIdx=-1,          # Draw all contours\n",
    "        color=(0, 255, 0),      # Green color (BGR)\n",
    "        thickness=2             # Line thickness\n",
    "    )\n",
    "    oriented_board = copy.deepcopy(img)\n",
    "    # Display results\n",
    "    rotation_code = 0\n",
    "    if index == 2:\n",
    "        rotation_code = 90  \n",
    "        oriented_board = cv2.rotate(oriented_board, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif index == 3:\n",
    "        rotation_code = 180  \n",
    "        oriented_board = cv2.rotate(oriented_board, cv2.ROTATE_180)\n",
    "    elif index == 1:\n",
    "        rotation_code = 260 \n",
    "        oriented_board = cv2.rotate(oriented_board, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    if(debug):\n",
    "        cv2.imshow(\"Image with Corner Boxes\", img)\n",
    "        cv2.imshow(\"Oriented Board\", oriented_board)\n",
    "        cv2.waitKey(0)\n",
    "        #cv2.imshow(\"Grayscale Version\", black_and_white)\n",
    "        #cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return oriented_board,rotation_code\n",
    "\n",
    "# Example usage:\n",
    "# image = cv2.imread(\"your_image.jpg\")\n",
    "# processed_image = findCorners(image, width_box=40, height_box=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed908f",
   "metadata": {},
   "source": [
    "# Yolov11M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a51e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1856x1856 3 white-pawns, 2 white-rooks, 1 white-knight, 1 white-king, 4 black-pawns, 2 black-rooks, 1 black-knight, 1 black-king, 142.0ms\n",
      "1: 1856x1856 1 white-pawn, 1 white-rook, 1 white-knight, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-knight, 1 black-king, 142.0ms\n",
      "2: 1856x1856 1 white-pawn, 1 white-rook, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-king, 142.0ms\n",
      "3: 1856x1856 6 white-pawns, 2 white-rooks, 1 white-knight, 1 white-bishop, 1 white-queen, 1 white-king, 6 black-pawns, 2 black-rooks, 1 black-knight, 1 black-bishop, 1 black-king, 1 black-king, 142.0ms\n",
      "Speed: 24.4ms preprocess, 142.0ms inference, 20.2ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 3 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-king, 124.7ms\n",
      "1: 1856x1856 2 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 1 black-pawn, 1 black-rook, 1 black-king, 124.7ms\n",
      "2: 1856x1856 4 white-pawns, 1 white-knight, 1 white-queen, 1 white-king, 4 black-pawns, 1 black-bishop, 1 black-king, 1 black-king, 124.7ms\n",
      "3: 1856x1856 7 white-pawns, 2 white-rooks, 2 white-knights, 2 white-bishops, 1 white-queen, 1 white-king, 7 black-pawns, 2 black-rooks, 2 black-knights, 2 black-bishops, 1 black-king, 1 black-king, 124.7ms\n",
      "Speed: 19.3ms preprocess, 124.7ms inference, 1.2ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 5 white-pawns, 2 white-rooks, 1 white-bishop, 1 white-queen, 1 white-king, 7 black-pawns, 1 black-rook, 1 black-knight, 1 black-bishop, 1 black-king, 1 black-king, 176.6ms\n",
      "1: 1856x1856 4 white-pawns, 1 white-rook, 1 white-queen, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-king, 1 black-king, 176.6ms\n",
      "2: 1856x1856 4 white-pawns, 1 white-rook, 1 white-queen, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-king, 1 black-king, 176.6ms\n",
      "3: 1856x1856 5 white-pawns, 2 white-rooks, 1 white-knight, 2 white-bishops, 1 white-queen, 1 white-king, 5 black-pawns, 2 black-rooks, 1 black-knight, 2 black-bishops, 1 black-king, 1 black-king, 176.6ms\n",
      "Speed: 22.5ms preprocess, 176.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 4 white-pawns, 1 white-king, 4 black-pawns, 1 black-king, 163.2ms\n",
      "1: 1856x1856 4 white-pawns, 1 white-king, 4 black-pawns, 1 black-king, 163.2ms\n",
      "2: 1856x1856 1 white-queen, 1 white-king, 3 black-pawns, 1 black-king, 163.2ms\n",
      "3: 1856x1856 4 white-pawns, 2 white-rooks, 1 white-bishop, 1 white-king, 2 black-pawns, 2 black-rooks, 1 black-knight, 1 black-king, 163.2ms\n",
      "Speed: 21.0ms preprocess, 163.2ms inference, 1.2ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 4 white-pawns, 2 white-rooks, 1 white-king, 2 black-pawns, 2 black-rooks, 1 black-king, 115.5ms\n",
      "1: 1856x1856 3 white-pawns, 2 white-rooks, 1 white-king, 1 black-pawn, 2 black-rooks, 1 black-king, 115.5ms\n",
      "2: 1856x1856 3 white-pawns, 2 white-rooks, 1 white-king, 1 black-pawn, 2 black-rooks, 1 black-king, 115.5ms\n",
      "3: 1856x1856 6 white-pawns, 2 white-rooks, 2 white-bishops, 1 white-king, 5 black-pawns, 2 black-rooks, 2 black-knights, 1 black-king, 115.5ms\n",
      "Speed: 19.0ms preprocess, 115.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 6 white-pawns, 1 white-rook, 2 white-bishops, 1 white-king, 5 black-pawns, 1 black-rook, 2 black-knights, 1 black-king, 118.3ms\n",
      "1: 1856x1856 2 white-pawns, 1 white-rook, 1 white-queen, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-king, 118.3ms\n",
      "2: 1856x1856 2 white-pawns, 1 white-rook, 1 white-queen, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-king, 118.3ms\n",
      "3: 1856x1856 6 white-pawns, 1 white-rook, 1 white-bishop, 1 white-king, 5 black-pawns, 2 black-rooks, 1 black-king, 118.3ms\n",
      "Speed: 20.5ms preprocess, 118.3ms inference, 1.3ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 4 white-pawns, 1 white-rook, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-king, 140.8ms\n",
      "1: 1856x1856 1 white-pawn, 1 white-rook, 1 white-king, 1 black-pawn, 1 black-rook, 1 black-king, 140.8ms\n",
      "2: 1856x1856 1 white-pawn, 1 white-rook, 1 white-king, 1 black-pawn, 1 black-rook, 1 black-king, 140.8ms\n",
      "3: 1856x1856 7 white-pawns, 2 white-rooks, 2 white-knights, 1 white-bishop, 1 white-queen, 1 white-king, 7 black-pawns, 2 black-rooks, 1 black-knight, 2 black-bishops, 1 black-king, 1 black-king, 140.8ms\n",
      "Speed: 24.4ms preprocess, 140.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 5 white-pawns, 1 white-bishop, 1 white-queen, 1 white-king, 6 black-pawns, 1 black-bishop, 1 black-king, 1 black-king, 115.2ms\n",
      "1: 1856x1856 5 white-pawns, 1 white-bishop, 1 white-queen, 1 white-king, 6 black-pawns, 1 black-bishop, 1 black-king, 1 black-king, 115.2ms\n",
      "2: 1856x1856 5 white-pawns, 1 white-rook, 1 white-knight, 1 white-bishop, 1 white-king, 4 black-pawns, 1 black-rook, 2 black-bishops, 1 black-king, 115.2ms\n",
      "3: 1856x1856 4 white-pawns, 1 white-bishop, 1 white-king, 3 black-pawns, 1 black-bishop, 1 black-king, 115.2ms\n",
      "Speed: 25.1ms preprocess, 115.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 2 white-pawns, 1 white-bishop, 1 white-king, 2 black-pawns, 1 black-bishop, 1 black-king, 115.9ms\n",
      "1: 1856x1856 4 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 5 black-pawns, 1 black-rook, 1 black-bishop, 1 black-king, 115.9ms\n",
      "2: 1856x1856 3 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-bishop, 1 black-king, 115.9ms\n",
      "3: 1856x1856 3 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-bishop, 1 black-king, 115.9ms\n",
      "Speed: 20.7ms preprocess, 115.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 3 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 4 black-pawns, 2 black-rooks, 1 black-king, 118.0ms\n",
      "1: 1856x1856 1 white-pawn, 1 white-rook, 1 white-knight, 1 white-king, 3 black-pawns, 2 black-rooks, 1 black-king, 118.0ms\n",
      "2: 1856x1856 6 white-pawns, 1 white-rook, 1 white-king, 5 black-pawns, 1 black-rook, 1 black-king, 118.0ms\n",
      "3: 1856x1856 5 white-pawns, 1 white-rook, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-king, 118.0ms\n",
      "Speed: 21.8ms preprocess, 118.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 5 white-pawns, 1 white-rook, 1 white-king, 4 black-pawns, 1 black-rook, 1 black-king, 137.3ms\n",
      "1: 1856x1856 2 white-pawns, 1 white-rook, 1 white-king, 2 black-pawns, 1 black-rook, 1 black-king, 137.3ms\n",
      "2: 1856x1856 4 white-pawns, 1 white-rook, 1 white-king, 2 black-pawns, 1 black-rook, 1 black-king, 137.3ms\n",
      "3: 1856x1856 2 white-pawns, 1 white-rook, 1 white-king, 2 black-pawns, 1 black-rook, 1 black-king, 137.3ms\n",
      "Speed: 52.5ms preprocess, 137.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 3 white-pawns, 2 white-rooks, 1 white-knight, 1 white-bishop, 1 white-king, 6 black-pawns, 2 black-rooks, 1 black-king, 1 black-king, 125.3ms\n",
      "1: 1856x1856 2 white-pawns, 2 white-rooks, 1 white-knight, 1 white-bishop, 1 white-king, 5 black-pawns, 2 black-rooks, 1 black-king, 1 black-king, 125.3ms\n",
      "2: 1856x1856 4 white-pawns, 1 white-rook, 2 white-bishops, 1 white-queen, 1 white-king, 6 black-pawns, 2 black-rooks, 1 black-knight, 1 black-king, 1 black-king, 125.3ms\n",
      "3: 1856x1856 2 white-pawns, 1 white-rook, 2 white-bishops, 1 white-queen, 1 white-king, 6 black-pawns, 2 black-rooks, 1 black-knight, 1 black-king, 1 black-king, 125.3ms\n",
      "Speed: 33.3ms preprocess, 125.3ms inference, 1.4ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "\n",
      "0: 1856x1856 2 white-pawns, 1 white-rook, 2 white-bishops, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-knight, 1 black-king, 119.0ms\n",
      "1: 1856x1856 5 white-pawns, 1 white-rook, 1 white-knight, 1 white-king, 3 black-pawns, 1 black-rook, 1 black-king, 119.0ms\n",
      "Speed: 44.5ms preprocess, 119.0ms inference, 1.1ms postprocess per image at shape (1, 3, 1856, 1856)\n",
      "Results saved to \u001b[1mruns\\detect\\predict33\u001b[0m\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "yoloResolution = 1856\n",
    "def runYoloOnImages(images):\n",
    "    results = []\n",
    "    model = YOLO(\"best.pt\")\n",
    "    batch_size = 4\n",
    "    # Calculate number of batches needed (rounding up)\n",
    "    num_batches = (len(images) + batch_size - 1) // batch_size\n",
    "\n",
    "    # Split into batches\n",
    "    batches = [images[i*batch_size : (i+1)*batch_size] \n",
    "            for i in range(num_batches)]\n",
    "\n",
    "    # Then process each batch\n",
    "    for batch in batches:\n",
    "        result = model.predict(batch, save=True, imgsz=yoloResolution, conf=0.6,batch=1)\n",
    "        results.extend(result)\n",
    "    return results\n",
    "yoloResults = runYoloOnImages(images)\n",
    "print(len(yoloResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba73396",
   "metadata": {},
   "source": [
    "# Convert yolo bounding boxes to contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2c2787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image:  ../images1/G000_IMG062.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G000_IMG087.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G000_IMG102.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G006_IMG048.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G006_IMG086.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G006_IMG119.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G019_IMG082.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G028_IMG015.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G028_IMG062.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G028_IMG098.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G028_IMG101.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G033_IMG043.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G033_IMG075.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G033_IMG088.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G033_IMG101.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G038_IMG074.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G038_IMG088.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G038_IMG103.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G038_IMG105.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G041_IMG042.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G041_IMG048.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G041_IMG088.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G041_IMG098.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G047_IMG053.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G047_IMG068.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G047_IMG102.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G047_IMG107.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G056_IMG017.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G056_IMG077.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G056_IMG097.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G058_IMG044.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G058_IMG074.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G058_IMG100.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G061_IMG080.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G061_IMG092.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G061_IMG098.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G072_IMG083.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G072_IMG098.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G076_IMG072.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G076_IMG089.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G076_IMG095.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G078_IMG092.jpg  with shape:  (3072, 3072, 3)\n",
      "Processing image:  ../images1/G083_IMG073.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G083_IMG089.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G087_IMG093.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G087_IMG099.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G091_IMG053.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G091_IMG074.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G091_IMG102.jpg  with shape:  (3024, 3024, 3)\n",
      "Processing image:  ../images1/G099_IMG094.jpg  with shape:  (3024, 3024, 3)\n"
     ]
    }
   ],
   "source": [
    "def rect_to_contour(x1, y1, x2, y2):\n",
    "    # Convert coordinates to integers\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    # Contour must be a numpy array of shape (N, 1, 2)\n",
    "    contour = np.array([\n",
    "        [[x1, y1]],  # Top-left\n",
    "        [[x2, y1]],  # Top-right\n",
    "        [[x2, y2]],  # Bottom-right\n",
    "        [[x1, y2]]   # Bottom-left\n",
    "    ], dtype=np.int32)\n",
    "    return contour\n",
    "YoloContours = []\n",
    "YoloBBids =  []\n",
    "for i,img in enumerate(images):\n",
    "    yoloResult = yoloResults[i]\n",
    "    if len(yoloResult.boxes) == 0:\n",
    "        print(\"No boxes detected in image: \", img)\n",
    "        continue\n",
    "    img_original = cv2.imread(img)\n",
    "    #img_original = cv2.resize(img_original, (yoloResolution, yoloResolution))\n",
    "    img_height, img_width = img_original.shape[:2]\n",
    "    print(\"Processing image: \", img, \" with shape: \", img_original.shape)\n",
    "    contours = []\n",
    "    BBids = []\n",
    "    for box in yoloResult.boxes:\n",
    "        xyxy = box.xyxy[0].cpu().numpy()\n",
    "        #print(\"Box coordinates: \", xyxy)\n",
    "        contour = rect_to_contour(xyxy[0], xyxy[1], xyxy[2], xyxy[3])\n",
    "        #print(\"Contour: \", contour)\n",
    "        contours.append(contour)\n",
    "        #print(int(box.cls.cpu()))\n",
    "        BBids.append(int(box.cls.cpu()))\n",
    "    YoloContours.append(contours)\n",
    "    YoloBBids.append(BBids)\n",
    "    #cv2.drawContours(img_original, contours, -1, (0, 255, 0), 4)\n",
    "    #img_original = cv2.resize(img_original, (720, 720), img_original)\n",
    "    #cv2.imshow(\"YOLO Boxes\", img_original)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8485217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_contours_to_warped_space(contours, M, fx=1, fy=1):\n",
    "    \"\"\"\n",
    "    Transforms contours from original image space to warped space.\n",
    "    \n",
    "    Args:\n",
    "        contours: List of contours (each as numpy array with shape (N,1,2))\n",
    "        M: Perspective transformation matrix (3x3)\n",
    "        fx: x-axis scale factor from warping (default=1)\n",
    "        fy: y-axis scale factor from warping (default=1)\n",
    "    \n",
    "    Returns:\n",
    "        List of transformed contours in warped image space\n",
    "    \"\"\"\n",
    "    warped_contours = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        # Convert contour to (N,2) format and float32\n",
    "        cnt_pts = cnt.reshape(-1, 2).astype(np.float32)\n",
    "        \n",
    "        # Apply perspective transform\n",
    "        warped_pts = cv2.perspectiveTransform(cnt_pts.reshape(1, -1, 2), M)[0]\n",
    "        \n",
    "        # Apply scaling if needed\n",
    "        if fx != 1 or fy != 1:\n",
    "            warped_pts[:, 0] *= fx\n",
    "            warped_pts[:, 1] *= fy\n",
    "        \n",
    "        # Reshape back to (N,1,2) and convert to integers\n",
    "        warped_cnt = warped_pts.reshape(-1, 1, 2).astype(np.int32)\n",
    "        warped_contours.append(warped_cnt)\n",
    "    \n",
    "    return warped_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c8a24",
   "metadata": {},
   "source": [
    "# IOU WITH YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565637a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chessboardPieces import drawSquares\n",
    "def compute_iou(contour1, contour2):\n",
    "    \"\"\"Compute Intersection over Union (IoU) between two contours.\"\"\"\n",
    "    # Create blank images\n",
    "    img1 = np.zeros((1000, 1000), dtype=np.uint8)  # Adjust size if needed\n",
    "    img2 = np.zeros((1000, 1000), dtype=np.uint8)\n",
    "    \n",
    "    # Draw contours\n",
    "    cv2.drawContours(img1, [contour1], -1, 255, -1)  # Filled contour\n",
    "    cv2.drawContours(img2, [contour2], -1, 255, -1)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = np.logical_and(img1, img2)\n",
    "    union = np.logical_or(img1, img2)\n",
    "    \n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou\n",
    "\n",
    "def getBestSquareByIou(contour, square_box,normalizedBoard):\n",
    "    row_idx = -1\n",
    "    bestIou = 0\n",
    "    bestPosition = None\n",
    "    normalizedBoard = copy.deepcopy(normalizedBoard)\n",
    "    for row in square_box:\n",
    "        row_idx += 1\n",
    "        column_idx = -1\n",
    "        for square in row:\n",
    "            column_idx += 1\n",
    "            if square is None:\n",
    "                #print(\"Square is None\")\n",
    "                continue\n",
    "            \"\"\"print(\"Debug Contour :\",square)\n",
    "            cv2.drawContours(normalizedBoard, [square], -1, (0, 255, 0), 4)\n",
    "            cv2.imshow(\"YOLO Boxes\", normalizedBoard)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\"\"\"\n",
    "            iou = compute_iou(contour, square)\n",
    "            if(iou > 0):\n",
    "                bestIou = iou\n",
    "                bestPosition = (row_idx, column_idx)\n",
    "    return bestPosition, bestIou\n",
    "\n",
    "def getBoardState(YoloBBids,warped_yoloBB, square_box, rotation,normalizedBoard):\n",
    "    result = [[12 for _ in range(8)] for _ in range(8)]\n",
    "    for id,contour in zip(YoloBBids,warped_yoloBB):\n",
    "        \"\"\"print(\"Debug Contour :\",contour)\n",
    "        cv2.drawContours(normalizedBoard, [contour], -1, (0, 255, 0), 4)\n",
    "        cv2.imshow(\"YOLO Boxes\", normalizedBoard)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\"\"\"\n",
    "\n",
    "        square_box_tmp = copy.deepcopy(square_box)\n",
    "        #square_box_tmp1 = copy.deepcopy(square_box)\n",
    "        #drawSquares(square_box_tmp1,copy.deepcopy(normalizedBoard))\n",
    "        point,iou =getBestSquareByIou(contour, square_box_tmp,normalizedBoard)\n",
    "        if point is None:\n",
    "            print(\"Continue\")\n",
    "            print(\"Debug Contour :\",contour)\n",
    "            cv2.drawContours(normalizedBoard, [contour], -1, (0, 255, 0), 4)\n",
    "            cv2.imshow(\"YOLO Boxes\", normalizedBoard)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            continue\n",
    "        if (result[point[0]][point[1]]!=12):\n",
    "            print(\"WARNING OVERRIDED\")\n",
    "        result[point[0]][point[1]] = id\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15df5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def drawBoard(matrix):\n",
    "    pathPieces = \"../assets/resources/pieces\"\n",
    "    pathBoard = \"../assets/resources/board.png\"\n",
    "    pieces = [\"white-pawn.png\",\"white-rook.png\",\"white-knight.png\",\"white-bishop.png\",\"white-queen.png\",\"white-king.png\",\"black-pawn.png\",\"black-rook.png\",\"black-knight.png\",\n",
    "             \"black-bishop.png\",\"black-queen.png\",\"black-king.png\"]\n",
    "    \n",
    "    # Load the board image\n",
    "    board = cv2.imread(pathBoard)\n",
    "    if board is None:\n",
    "        raise FileNotFoundError(f\"Board image not found at {pathBoard}\")\n",
    "    \n",
    "    height, width = board.shape[:2]\n",
    "    square_size = height // 8  # Assuming a standard 8x8 chess board\n",
    "    \n",
    "    # Load and resize all piece images\n",
    "    piece_images = []\n",
    "    for piece in pieces:\n",
    "        piece_path = f\"{pathPieces}/{piece}\"\n",
    "        img = cv2.imread(piece_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Piece image not found at {piece_path}\")\n",
    "        # Resize piece to fit the square\n",
    "        img = cv2.resize(img, (square_size, square_size))\n",
    "        piece_images.append(img)\n",
    "    \n",
    "    # Draw pieces on the board based on the matrix\n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            piece_index = matrix[row][col]\n",
    "            if piece_index != 12:  # Assuming -1 or similar means no piece\n",
    "                # Calculate position\n",
    "                x = col * square_size\n",
    "                y = row * square_size\n",
    "                \n",
    "                # Get the appropriate piece image\n",
    "                piece_img = piece_images[piece_index]\n",
    "                \n",
    "                # If the image has an alpha channel (transparency)\n",
    "                if piece_img.shape[2] == 4:\n",
    "                    # Overlay the piece with transparency handling\n",
    "                    overlay_img = piece_img[:, :, :3]\n",
    "                    mask = piece_img[:, :, 3] / 255.0\n",
    "                    \n",
    "                    # Get the region of interest\n",
    "                    roi = board[y:y+square_size, x:x+square_size]\n",
    "                    \n",
    "                    # Blend the images\n",
    "                    for c in range(3):\n",
    "                        roi[:, :, c] = roi[:, :, c] * (1 - mask) + overlay_img[:, :, c] * mask\n",
    "                else:\n",
    "                    # No alpha channel, simple overlay\n",
    "                    board[y:y+square_size, x:x+square_size] = piece_img\n",
    "    \n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c566e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image:  ../images1/G000_IMG062.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G000_IMG087.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G000_IMG102.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G006_IMG048.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "WARNING OVERRIDED\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G006_IMG086.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G006_IMG119.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G019_IMG082.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G028_IMG015.jpg\n",
      "Processing image:  ../images1/G028_IMG062.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G028_IMG098.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G028_IMG101.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G033_IMG043.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G033_IMG075.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G033_IMG088.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G033_IMG101.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G038_IMG074.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G038_IMG088.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G038_IMG103.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G038_IMG105.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G041_IMG042.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G041_IMG048.jpg\n",
      "All squares found\n",
      "WARNING OVERRIDED\n",
      "WARNING OVERRIDED\n",
      "Processing image:  ../images1/G041_IMG088.jpg\n",
      "All squares found\n",
      "Processing image:  ../images1/G041_IMG098.jpg\n",
      "All squares found\n"
     ]
    }
   ],
   "source": [
    "from task3_2API import detectBoardAndSquares\n",
    "from chessboardPieces import drawSquares\n",
    "for index,img in enumerate(images):\n",
    "    print(\"Processing image: \", img)\n",
    "    yoloBB = YoloContours[index]\n",
    "    yoloBBid = YoloBBids[index]\n",
    "    # Call the function to detect board and squares\n",
    "    normalizedBoard, square_box, M, fx, fy = detectBoardAndSquares(img)\n",
    "    if(normalizedBoard is not None):\n",
    "        \n",
    "        orientedBoard,rotation  =findHorse(normalizedBoard,10,5,45,70,debug=False)\n",
    "        \"\"\"cv2.imshow(\"Oriented Board\", orientedBoard)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\"\"\"\n",
    "        warped_yoloBB = transform_contours_to_warped_space(yoloBB, M, fy, fx)\n",
    "        \"\"\"cv2.drawContours(normalizedBoard, warped_yoloBB, -1, (0, 255, 0), 4)\n",
    "        normalizedBoard1 = cv2.resize(normalizedBoard, (720, 720), normalizedBoard)\n",
    "        cv2.imshow(\"YOLO Boxes\", normalizedBoard1)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\"\"\"\n",
    "        square_box2 = copy.deepcopy(square_box)\n",
    "        #square_box1 = copy.deepcopy(square_box)\n",
    "        #drawSquares(square_box1,copy.deepcopy(normalizedBoard))\n",
    "        matrix = getBoardState(yoloBBid,warped_yoloBB, square_box2, rotation,normalizedBoard)\n",
    "        board = drawBoard(matrix)\n",
    "        cv2.imshow(\"Ground Truth \", normalizedBoard)\n",
    "        cv2.imshow(\"Result\", board)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "# Print column by column\n",
    "\"\"\"\n",
    "        for col in range(8):\n",
    "            for row in range(8):\n",
    "                print(matrix[row][col], end=' ')\n",
    "            print() \"\"\" # New line after each column\n",
    "                #drawSquares(square_box,normalizedBoard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
