{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23543a00",
   "metadata": {},
   "source": [
    "# Faster R-CNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59faed2",
   "metadata": {},
   "source": [
    "## Transforms / Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72025cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms._presets.ObjectDetection'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt, numpy as np, os, torch, random, cv2, json\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2 as transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "num_classes = 12\n",
    "weights = torchvision.models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2( weights=weights)\n",
    "# Replace the classifier with a new one for your number of classes\n",
    "transforms1 = weights.transforms\n",
    "print(transforms1)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "data_aug = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0), ratio=(0.95, 1.05)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_in = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914e344",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e9ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 10\n",
      "Number of valid images: 10\n",
      "Number of test images: 10\n"
     ]
    }
   ],
   "source": [
    "def convert_bbox_format(bbox):\n",
    "    \"\"\"\n",
    "    Convert [x, y, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    \n",
    "    Args:\n",
    "        bbox (list): [x_center, y_center, width, height]\n",
    "    \n",
    "    Returns:\n",
    "        list: [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    x_min = x\n",
    "    y_min = y\n",
    "    x_max = x + w\n",
    "    y_max = y + h\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, root_dir, partition, transform=None):\n",
    "        self.anns = json.load(open(os.path.join(root_dir, 'annotations.json')))\n",
    "        self.categories = [c['name'] for c in self.anns['categories']]\n",
    "        self.root = root_dir\n",
    "        self.ids = []\n",
    "        self.file_names = []\n",
    "        for x in self.anns['images']:\n",
    "            self.file_names.append(x['path'])\n",
    "            self.ids.append(x['id'])\n",
    "        self.file_names = np.asarray(self.file_names)\n",
    "        self.ids = np.asarray(self.ids)\n",
    "        # create a list of size num_images, each element is a list of pieces\n",
    "        self.boardLabels = [[] for _ in range(len(self.ids))]\n",
    "        self.boardBB = [[] for _ in range(len(self.ids))]\n",
    "        for piece in self.anns['annotations']['pieces']:\n",
    "            idx = np.where(self.ids == piece['image_id'])[0][0]\n",
    "            if \"bbox\" in piece.keys():\n",
    "                bbox = convert_bbox_format(piece['bbox'])\n",
    "                self.boardBB[idx].append(bbox)\n",
    "                self.boardLabels[idx].append(piece['category_id'])\n",
    "        if partition == 'train':\n",
    "            self.split_ids = np.asarray(self.anns['splits'][\"chessred2k\"]['train']['image_ids']).astype(int)\n",
    "        elif partition == 'valid':\n",
    "            self.split_ids = np.asarray(self.anns['splits'][\"chessred2k\"]['val']['image_ids']).astype(int)\n",
    "        else:\n",
    "            self.split_ids = np.asarray(self.anns['splits'][\"chessred2k\"]['test']['image_ids']).astype(int)\n",
    "        self.split_ids = self.split_ids[:10]\n",
    "        intersect = np.isin(self.ids, self.split_ids)\n",
    "        self.split_ids = np.where(intersect)[0]\n",
    "        self.file_names = [self.file_names[i] for i in self.split_ids]\n",
    "        self.boardBB = [self.boardBB[i] for i in self.split_ids]\n",
    "        self.boardLabels = [self.boardLabels[i] for i in self.split_ids]\n",
    "        #self.num_pieces = F.one_hot(self.num_pieces.long()-1, 32)\n",
    "        self.ids = self.ids[self.split_ids]\n",
    "\n",
    "        self.transform = transform\n",
    "        print(f\"Number of {partition} images: {len(self.file_names)}\")\n",
    "        self.images = {}\n",
    "        for i in range(len(self.file_names)):\n",
    "            #image = cv2.imread(os.path.join(self.root, self.file_names[i]))\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = Image.open(os.path.join(self.root, self.file_names[i]))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            self.images[self.file_names[i]] = image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = self.images[self.file_names[i]]\n",
    "        boxes = self.boardBB[i]\n",
    "        labels = self.boardLabels[i]\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image\"] = image\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "            \n",
    "        return target\n",
    "\n",
    "train_dataset = ChessDataset('..', 'train', data_aug)\n",
    "valid_dataset = ChessDataset('..', 'valid', data_in)\n",
    "test_dataset = ChessDataset('..', 'test', data_in)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batchsize = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batchsize, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72efba",
   "metadata": {},
   "source": [
    "# train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f40edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
    "    if is_train:\n",
    "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
    "      \n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    if is_train:\n",
    "      model.train() # put model in train mode\n",
    "    else:\n",
    "      model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "          images = list(image.to(device) for image in images)\n",
    "          targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "          \n",
    "          # Zero gradients\n",
    "          optimizer.zero_grad()\n",
    "          \n",
    "          # Forward pass\n",
    "          loss_dict = model(images, targets)\n",
    "          loss = sum(loss for loss in loss_dict.values())\n",
    "          if is_train:\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "          # Save training metrics\n",
    "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
    "\n",
    "          preds.extend(loss.cpu().detach().numpy())\n",
    "          labels.extend(y.cpu().numpy())\n",
    "    print(\"Preds\",preds )\n",
    "    pred_average = np.average(preds)\n",
    "    return total_loss / num_batches, pred_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32078f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer):\n",
    "  train_history = {'loss': [], 'accuracy': []}\n",
    "  val_history = {'loss': [], 'accuracy': []}\n",
    "  best_val_loss = np.inf\n",
    "  print(\"Start training...\")\n",
    "  for t in range(num_epochs):\n",
    "      print(f\"\\nEpoch {t+1}\")\n",
    "      train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
    "      print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
    "      val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
    "      print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
    "\n",
    "      # save model when val loss improves\n",
    "      if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "        torch.save(save_dict, model_name + '_best_model.pth')\n",
    "\n",
    "      # save latest model\n",
    "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "      torch.save(save_dict, model_name + '_latest_model.pth')\n",
    "\n",
    "      # save training history for plotting purposes\n",
    "      train_history[\"loss\"].append(train_loss)\n",
    "      train_history[\"accuracy\"].append(train_acc)\n",
    "\n",
    "      val_history[\"loss\"].append(val_loss)\n",
    "      val_history[\"accuracy\"].append(val_acc)\n",
    "      \n",
    "  print(\"Finished\")\n",
    "  return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd03f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.MSELoss()\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "num_epochs = 100\n",
    "\n",
    "# TODO - Train the model\n",
    "train_history, val_history = train(model, 'chess_model', num_epochs, train_dataloader, valid_dataloader, loss_fn, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
